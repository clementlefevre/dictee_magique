{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev0\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Synthesizes speech from the input string of text or ssml.\n",
    "\n",
    "Note: ssml must be well-formed according to:\n",
    "    https://www.w3.org/TR/speech-synthesis/\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from google.cloud import texttospeech\n",
    "import pygame\n",
    "import string\n",
    "import configparser\n",
    "\n",
    "\n",
    "\n",
    "# Instantiates a client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "pygame.mixer.init(frequency=44000)\n",
    "\n",
    "\n",
    "def store_text(text_to_store, filename=None, folder = None):\n",
    "    \n",
    "    folderpath = \"data/sounds/\"+folder\n",
    "    print(folderpath)\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "\n",
    "    # Set the text input to be synthesized\n",
    "    synthesis_input = texttospeech.types.SynthesisInput(text=text_to_store)\n",
    "\n",
    "    # Build the voice request, select the language code (\"en-US\") and the ssml\n",
    "    # voice gender (\"neutral\")\n",
    "    voice = texttospeech.types.VoiceSelectionParams(\n",
    "        language_code=\"fr-fr\", ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "\n",
    "    # Select the type of audio file you want returned\n",
    "    audio_config = texttospeech.types.AudioConfig(\n",
    "        sample_rate_hertz=44100,\n",
    "        audio_encoding=texttospeech.enums.AudioEncoding.LINEAR16,\n",
    "    )\n",
    "\n",
    "    # Perform the text-to-speech request on the text input with the selected\n",
    "    # voice parameters and audio file type\n",
    "    response = client.synthesize_speech(synthesis_input, voice, audio_config)\n",
    "    if filename is None:\n",
    "\n",
    "        filename = str(text_to_store)\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(\"data/sounds/\" +folder+\"/\" + filename + \".wav\", \"wb\") as out:\n",
    "\n",
    "        # Write the response to the output file.\n",
    "        out.write(response.audio_content)\n",
    "        print(f\"Audio content written to file {filename}\")\n",
    "\n",
    "\n",
    "def scrap_alphabet():\n",
    "    for letter in string.ascii_lowercase:\n",
    "        store_text(letter)\n",
    "\n",
    "def read_config_file():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../model/text_content.ini')\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/text_content.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../model/text_content.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GREETINGS',\n",
       " 'ANSWERS_OK',\n",
       " 'ANSWERS_NOK',\n",
       " 'INTRO',\n",
       " 'SCORE',\n",
       " 'SCORE_INFOS',\n",
       " 'QUESTIONS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'GREETINGS'\n",
    "for s in config.sections():\n",
    "    for k,v in config[s].items():\n",
    "        #store_text(v,k,s)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "result = [y for x in os.walk('data/sounds') for y in glob(os.path.join(x[0], '*.wav'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpy\n",
    "def slow_speed(file,speed_ratio):\n",
    "    target_file = file.split('/')[-1]\n",
    "    target_folder = '/'.join([file.split('/')[0],file.split('/')[1]])\n",
    "    \n",
    "    print(target_file)\n",
    "    print(target_folder)\n",
    "    target_path = target_folder+\"/\"+target_file.split(\".\")[0]+\"_slow.wav\"\n",
    "    print (target_path)\n",
    "    ff = ffmpy.FFmpeg(inputs={file: None}, outputs={target_path: [\"-filter:a\", \"atempo=0.8\"]})\n",
    "    ff.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nok_4.wav\n",
      "data/sounds\n",
      "data/sounds/nok_4_robotic.wav\n"
     ]
    },
    {
     "ename": "FFRuntimeError",
     "evalue": "`ffmpeg -i data/sounds/ANSWERS_NOK/nok_4.wav -filter:a atempo=0.8 data/sounds/nok_4_robotic.wav` exited with status 1\n\nSTDOUT:\n\n\nSTDERR:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFFRuntimeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0a82746e8062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslow_speed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b2f571fd9958>\u001b[0m in \u001b[0;36mslow_speed\u001b[0;34m(file, speed_ratio)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFmpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"-filter:a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"atempo=0.8\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/speak_n_spell/env/lib/python3.7/site-packages/ffmpy.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, input_data, stdout, stderr)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFFRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFFRuntimeError\u001b[0m: `ffmpeg -i data/sounds/ANSWERS_NOK/nok_4.wav -filter:a atempo=0.8 data/sounds/nok_4_robotic.wav` exited with status 1\n\nSTDOUT:\n\n\nSTDERR:\n"
     ]
    }
   ],
   "source": [
    "slow_speed(result[0],0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/sounds/ANSWERS_NOK/nok_4.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sounds/ANSWERS_NOK/nok_4.wav\n",
      "data/sounds/ANSWERS_NOK/nok_2.wav\n",
      "data/sounds/ANSWERS_NOK/nok_5.wav\n",
      "data/sounds/ANSWERS_NOK/nok_3.wav\n",
      "data/sounds/ANSWERS_NOK/nok_1.wav\n",
      "data/sounds/GREETINGS/bonjour_1.wav\n",
      "data/sounds/GREETINGS/bonjour_4.wav\n",
      "data/sounds/GREETINGS/bonjour_3.wav\n",
      "data/sounds/GREETINGS/bonjour_5.wav\n",
      "data/sounds/GREETINGS/bonjour_2.wav\n",
      "data/sounds/GREETINGS/out.wav\n",
      "data/sounds/INTRO/intro_1.wav\n",
      "data/sounds/INTRO/intro_3.wav\n",
      "data/sounds/INTRO/intro_4.wav\n",
      "data/sounds/INTRO/intro_2.wav\n",
      "data/sounds/QUESTIONS/q_13.wav\n",
      "data/sounds/QUESTIONS/q_4.wav\n",
      "data/sounds/QUESTIONS/q_14.wav\n",
      "data/sounds/QUESTIONS/q_17.wav\n",
      "data/sounds/QUESTIONS/q_19.wav\n",
      "data/sounds/QUESTIONS/q_18.wav\n",
      "data/sounds/QUESTIONS/q_12.wav\n",
      "data/sounds/QUESTIONS/q_3.wav\n",
      "data/sounds/QUESTIONS/q_9.wav\n",
      "data/sounds/QUESTIONS/q_10.wav\n",
      "data/sounds/QUESTIONS/q_2.wav\n",
      "data/sounds/QUESTIONS/q_11.wav\n",
      "data/sounds/QUESTIONS/q_20.wav\n",
      "data/sounds/QUESTIONS/q_21.wav\n",
      "data/sounds/QUESTIONS/q_15.wav\n",
      "data/sounds/QUESTIONS/q_16.wav\n",
      "data/sounds/QUESTIONS/q_1.wav\n",
      "data/sounds/QUESTIONS/q_5.wav\n",
      "data/sounds/QUESTIONS/q_7.wav\n",
      "data/sounds/QUESTIONS/q_8.wav\n",
      "data/sounds/QUESTIONS/q_6.wav\n",
      "data/sounds/SCORE/score_1.wav\n",
      "data/sounds/SCORE/score_2.wav\n",
      "data/sounds/SCORE/score_3.wav\n",
      "data/sounds/SCORE_INFOS/score_infos_1.wav\n",
      "data/sounds/SCORE_INFOS/score_infos_2.wav\n",
      "data/sounds/ANSWERS_OK/ok_4.wav\n",
      "data/sounds/ANSWERS_OK/ok_1.wav\n",
      "data/sounds/ANSWERS_OK/ok_3.wav\n",
      "data/sounds/ANSWERS_OK/ok_2.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for r in result:\n",
    "    try:\n",
    "        slow_speed(r,0.8)\n",
    "    except :\n",
    "        print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak_n_spell",
   "language": "python",
   "name": "speak_n_spell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
