{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0.dev0\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Synthesizes speech from the input string of text or ssml.\n",
    "\n",
    "Note: ssml must be well-formed according to:\n",
    "    https://www.w3.org/TR/speech-synthesis/\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from google.cloud import texttospeech\n",
    "import pygame\n",
    "import string\n",
    "import configparser\n",
    "\n",
    "\n",
    "\n",
    "# Instantiates a client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "pygame.mixer.init(frequency=44000)\n",
    "\n",
    "\n",
    "def store_text(text_to_store, filename=None, folder = None):\n",
    "    \n",
    "    folderpath = \"data/sounds/\"+folder\n",
    "    print(folderpath)\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "\n",
    "    # Set the text input to be synthesized\n",
    "    synthesis_input = texttospeech.types.SynthesisInput(text=text_to_store)\n",
    "\n",
    "    # Build the voice request, select the language code (\"en-US\") and the ssml\n",
    "    # voice gender (\"neutral\")\n",
    "    voice = texttospeech.types.VoiceSelectionParams(\n",
    "        language_code=\"fr-fr\", ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "\n",
    "    # Select the type of audio file you want returned\n",
    "    audio_config = texttospeech.types.AudioConfig(\n",
    "        sample_rate_hertz=44100,\n",
    "        audio_encoding=texttospeech.enums.AudioEncoding.LINEAR16,\n",
    "    )\n",
    "\n",
    "    # Perform the text-to-speech request on the text input with the selected\n",
    "    # voice parameters and audio file type\n",
    "    response = client.synthesize_speech(synthesis_input, voice, audio_config)\n",
    "    if filename is None:\n",
    "\n",
    "        filename = str(text_to_store)\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(\"data/sounds/\" +folder+\"/\" + filename + \".wav\", \"wb\") as out:\n",
    "\n",
    "        # Write the response to the output file.\n",
    "        out.write(response.audio_content)\n",
    "        print(f\"Audio content written to file {filename}\")\n",
    "\n",
    "\n",
    "def scrap_alphabet():\n",
    "    for letter in string.ascii_lowercase:\n",
    "        store_text(letter)\n",
    "\n",
    "def read_config_file():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../model/text_content.ini')\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/text_content.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../model/text_content.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GREETINGS',\n",
       " 'ANSWERS_OK',\n",
       " 'ANSWERS_NOK',\n",
       " 'INTRO',\n",
       " 'SCORE',\n",
       " 'SCORE_INFOS',\n",
       " 'QUESTIONS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'GREETINGS'\n",
    "for s in config.sections():\n",
    "    for k,v in config[s].items():\n",
    "        #store_text(v,k,s)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "result = [y for x in os.walk('data/sounds') for y in glob(os.path.join(x[0], '*.wav'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpy\n",
    "def slow_speed(file,speed_ratio):\n",
    "    target_file = file.split('/')[-1]\n",
    "    target_folder = '/'.join(file.split('/')[0:3])\n",
    "    \n",
    "    print(target_file)\n",
    "    print(target_folder)\n",
    "    target_path = target_folder+\"/\"+target_file.split(\".\")[0]+\"_slow.wav\"\n",
    "    print (target_path)\n",
    "    ff = ffmpy.FFmpeg(inputs={file: None}, outputs={target_path: [\"-filter:a\", \"atempo=0.8\"]})\n",
    "    ff.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = result[0].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/sounds/ANSWERS_NOK'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(l[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nok_4.wav\n",
      "data/sounds/ANSWERS_NOK\n",
      "data/sounds/ANSWERS_NOK/nok_4_slow.wav\n"
     ]
    }
   ],
   "source": [
    "slow_speed(result[0],0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/sounds/ANSWERS_NOK/nok_4.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nok_4.wav\n",
      "data/sounds/ANSWERS_NOK\n",
      "data/sounds/ANSWERS_NOK/nok_4_slow.wav\n",
      "data/sounds/ANSWERS_NOK/nok_4.wav\n",
      "nok_2.wav\n",
      "data/sounds/ANSWERS_NOK\n",
      "data/sounds/ANSWERS_NOK/nok_2_slow.wav\n",
      "nok_5.wav\n",
      "data/sounds/ANSWERS_NOK\n",
      "data/sounds/ANSWERS_NOK/nok_5_slow.wav\n",
      "nok_3.wav\n",
      "data/sounds/ANSWERS_NOK\n",
      "data/sounds/ANSWERS_NOK/nok_3_slow.wav\n",
      "nok_1.wav\n",
      "data/sounds/ANSWERS_NOK\n",
      "data/sounds/ANSWERS_NOK/nok_1_slow.wav\n",
      "bonjour_1.wav\n",
      "data/sounds/GREETINGS\n",
      "data/sounds/GREETINGS/bonjour_1_slow.wav\n",
      "bonjour_4.wav\n",
      "data/sounds/GREETINGS\n",
      "data/sounds/GREETINGS/bonjour_4_slow.wav\n",
      "bonjour_3.wav\n",
      "data/sounds/GREETINGS\n",
      "data/sounds/GREETINGS/bonjour_3_slow.wav\n",
      "bonjour_5.wav\n",
      "data/sounds/GREETINGS\n",
      "data/sounds/GREETINGS/bonjour_5_slow.wav\n",
      "bonjour_2.wav\n",
      "data/sounds/GREETINGS\n",
      "data/sounds/GREETINGS/bonjour_2_slow.wav\n",
      "out.wav\n",
      "data/sounds/GREETINGS\n",
      "data/sounds/GREETINGS/out_slow.wav\n",
      "intro_1.wav\n",
      "data/sounds/INTRO\n",
      "data/sounds/INTRO/intro_1_slow.wav\n",
      "intro_3.wav\n",
      "data/sounds/INTRO\n",
      "data/sounds/INTRO/intro_3_slow.wav\n",
      "intro_4.wav\n",
      "data/sounds/INTRO\n",
      "data/sounds/INTRO/intro_4_slow.wav\n",
      "intro_2.wav\n",
      "data/sounds/INTRO\n",
      "data/sounds/INTRO/intro_2_slow.wav\n",
      "q_13.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_13_slow.wav\n",
      "q_4.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_4_slow.wav\n",
      "q_14.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_14_slow.wav\n",
      "q_17.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_17_slow.wav\n",
      "q_19.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_19_slow.wav\n",
      "q_18.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_18_slow.wav\n",
      "q_12.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_12_slow.wav\n",
      "q_3.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_3_slow.wav\n",
      "q_9.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_9_slow.wav\n",
      "q_10.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_10_slow.wav\n",
      "q_2.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_2_slow.wav\n",
      "q_11.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_11_slow.wav\n",
      "q_20.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_20_slow.wav\n",
      "q_21.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_21_slow.wav\n",
      "q_15.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_15_slow.wav\n",
      "q_16.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_16_slow.wav\n",
      "q_1.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_1_slow.wav\n",
      "q_5.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_5_slow.wav\n",
      "q_7.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_7_slow.wav\n",
      "q_8.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_8_slow.wav\n",
      "q_6.wav\n",
      "data/sounds/QUESTIONS\n",
      "data/sounds/QUESTIONS/q_6_slow.wav\n",
      "score_1.wav\n",
      "data/sounds/SCORE\n",
      "data/sounds/SCORE/score_1_slow.wav\n",
      "score_2.wav\n",
      "data/sounds/SCORE\n",
      "data/sounds/SCORE/score_2_slow.wav\n",
      "score_3.wav\n",
      "data/sounds/SCORE\n",
      "data/sounds/SCORE/score_3_slow.wav\n",
      "score_infos_1.wav\n",
      "data/sounds/SCORE_INFOS\n",
      "data/sounds/SCORE_INFOS/score_infos_1_slow.wav\n",
      "score_infos_2.wav\n",
      "data/sounds/SCORE_INFOS\n",
      "data/sounds/SCORE_INFOS/score_infos_2_slow.wav\n",
      "ok_4.wav\n",
      "data/sounds/ANSWERS_OK\n",
      "data/sounds/ANSWERS_OK/ok_4_slow.wav\n",
      "ok_1.wav\n",
      "data/sounds/ANSWERS_OK\n",
      "data/sounds/ANSWERS_OK/ok_1_slow.wav\n",
      "ok_3.wav\n",
      "data/sounds/ANSWERS_OK\n",
      "data/sounds/ANSWERS_OK/ok_3_slow.wav\n",
      "ok_2.wav\n",
      "data/sounds/ANSWERS_OK\n",
      "data/sounds/ANSWERS_OK/ok_2_slow.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for r in result:\n",
    "    try:\n",
    "        slow_speed(r,0.8)\n",
    "    except :\n",
    "        print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak_n_spell",
   "language": "python",
   "name": "speak_n_spell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
